{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "482c6309-f435-4eb7-82d6-addc8a2c4a79",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "# Natural Language Toolkit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bb475067-7ac6-4330-a747-bd84dd012f6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install nltk"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "040bfdd0-7ccc-400f-8726-a309992107a4",
   "metadata": {},
   "source": [
    "## Tokenisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "05b29040-1419-4593-a94c-e894c2d507c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At nine o'clock, I visited him myself. It looks like religious mania, and he'll soon think that he himself is God.\n"
     ]
    }
   ],
   "source": [
    "document = \"At nine o'clock, I visited him myself. It looks like religious mania, and he'll soon think that he himself is God.\"\n",
    "print(document)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "401fbe85-0c35-428c-b087-1f9ce84256f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['At', 'nine', \"o'clock,\", 'I', 'visited', 'him', 'myself.', 'It', 'looks', 'like', 'religious', 'mania,', 'and', \"he'll\", 'soon', 'think', 'that', 'he', 'himself', 'is', 'God.']\n"
     ]
    }
   ],
   "source": [
    "print(document.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "64feb075-2bdf-4003-8829-8b304ea6a120",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/shivamgarg/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('punkt')# model\n",
    "# pre-trained model available in nltk for tokenisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e8aad4a-70c6-4a28-9a26-1fbf2cd0a8a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#nltk.download('punkt_tab')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ee391652-1cab-4483-aca3-57529f76f958",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['At', 'nine', \"o'clock\", ',', 'I', 'visited', 'him', 'myself', '.', 'It', 'looks', 'like', 'religious', 'mania', ',', 'and', 'he', \"'ll\", 'soon', 'think', 'that', 'he', 'himself', 'is', 'God', '.']\n"
     ]
    }
   ],
   "source": [
    "from nltk.tokenize import word_tokenize #code\n",
    "words = word_tokenize(document)\n",
    "print(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2ebf329a-890c-4e05-93f1-a9566b21d729",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"At nine o'clock, I visited him myself.\", \"It looks like religious mania, and he'll soon think that he himself is God.\"]\n"
     ]
    }
   ],
   "source": [
    "from nltk.tokenize import sent_tokenize #code\n",
    "words = sent_tokenize(document)\n",
    "print(words)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "147b6c63-67e2-451a-9bf2-7c3631a5407b",
   "metadata": {},
   "source": [
    "## StopWords Removal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "755fc333-1421-4a61-938d-89ace9f485db",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/shivamgarg/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download(\"stopwords\")# data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3cad5644-3c61-451a-904d-38210d03adcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords # code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "466cbdb6-fdbd-4264-92b3-e59e3424361f",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\", \"you'll\", \"you'd\", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', \"she's\", 'her', 'hers', 'herself', 'it', \"it's\", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', \"that'll\", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', \"don't\", 'should', \"should've\", 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', \"aren't\", 'couldn', \"couldn't\", 'didn', \"didn't\", 'doesn', \"doesn't\", 'hadn', \"hadn't\", 'hasn', \"hasn't\", 'haven', \"haven't\", 'isn', \"isn't\", 'ma', 'mightn', \"mightn't\", 'mustn', \"mustn't\", 'needn', \"needn't\", 'shan', \"shan't\", 'shouldn', \"shouldn't\", 'wasn', \"wasn't\", 'weren', \"weren't\", 'won', \"won't\", 'wouldn', \"wouldn't\"]\n"
     ]
    }
   ],
   "source": [
    "print(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "14ef0ef0-a684-4e2d-9201-29233004c08f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "179"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ls=stopwords.words('english')\n",
    "len(ls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "7072bcb7-d541-4fbf-8038-7544d69e4f40",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['i',\n",
       " 'me',\n",
       " 'my',\n",
       " 'myself',\n",
       " 'we',\n",
       " 'our',\n",
       " 'ours',\n",
       " 'ourselves',\n",
       " 'you',\n",
       " \"you're\",\n",
       " \"you've\",\n",
       " \"you'll\",\n",
       " \"you'd\",\n",
       " 'your',\n",
       " 'yours',\n",
       " 'yourself',\n",
       " 'yourselves',\n",
       " 'he',\n",
       " 'him',\n",
       " 'his',\n",
       " 'himself',\n",
       " 'she',\n",
       " \"she's\",\n",
       " 'her',\n",
       " 'hers',\n",
       " 'herself',\n",
       " 'it',\n",
       " \"it's\",\n",
       " 'its',\n",
       " 'itself',\n",
       " 'they',\n",
       " 'them',\n",
       " 'their',\n",
       " 'theirs',\n",
       " 'themselves',\n",
       " 'what',\n",
       " 'which',\n",
       " 'who',\n",
       " 'whom',\n",
       " 'this',\n",
       " 'that',\n",
       " \"that'll\",\n",
       " 'these',\n",
       " 'those',\n",
       " 'am',\n",
       " 'is',\n",
       " 'are',\n",
       " 'was',\n",
       " 'were',\n",
       " 'be',\n",
       " 'been',\n",
       " 'being',\n",
       " 'have',\n",
       " 'has',\n",
       " 'had',\n",
       " 'having',\n",
       " 'do',\n",
       " 'does',\n",
       " 'did',\n",
       " 'doing',\n",
       " 'a',\n",
       " 'an',\n",
       " 'the',\n",
       " 'and',\n",
       " 'but',\n",
       " 'if',\n",
       " 'or',\n",
       " 'because',\n",
       " 'as',\n",
       " 'until',\n",
       " 'while',\n",
       " 'of',\n",
       " 'at',\n",
       " 'by',\n",
       " 'for',\n",
       " 'with',\n",
       " 'about',\n",
       " 'against',\n",
       " 'between',\n",
       " 'into',\n",
       " 'through',\n",
       " 'during',\n",
       " 'before',\n",
       " 'after',\n",
       " 'above',\n",
       " 'below',\n",
       " 'to',\n",
       " 'from',\n",
       " 'up',\n",
       " 'down',\n",
       " 'in',\n",
       " 'out',\n",
       " 'on',\n",
       " 'off',\n",
       " 'over',\n",
       " 'under',\n",
       " 'again',\n",
       " 'further',\n",
       " 'then',\n",
       " 'once',\n",
       " 'here',\n",
       " 'there',\n",
       " 'when',\n",
       " 'where',\n",
       " 'why',\n",
       " 'how',\n",
       " 'all',\n",
       " 'any',\n",
       " 'both',\n",
       " 'each',\n",
       " 'few',\n",
       " 'more',\n",
       " 'most',\n",
       " 'other',\n",
       " 'some',\n",
       " 'such',\n",
       " 'no',\n",
       " 'nor',\n",
       " 'not',\n",
       " 'only',\n",
       " 'own',\n",
       " 'same',\n",
       " 'so',\n",
       " 'than',\n",
       " 'too',\n",
       " 'very',\n",
       " 's',\n",
       " 't',\n",
       " 'can',\n",
       " 'will',\n",
       " 'just',\n",
       " 'don',\n",
       " \"don't\",\n",
       " 'should',\n",
       " \"should've\",\n",
       " 'now',\n",
       " 'd',\n",
       " 'll',\n",
       " 'm',\n",
       " 'o',\n",
       " 're',\n",
       " 've',\n",
       " 'y',\n",
       " 'ain',\n",
       " 'aren',\n",
       " \"aren't\",\n",
       " 'couldn',\n",
       " \"couldn't\",\n",
       " 'didn',\n",
       " \"didn't\",\n",
       " 'doesn',\n",
       " \"doesn't\",\n",
       " 'hadn',\n",
       " \"hadn't\",\n",
       " 'hasn',\n",
       " \"hasn't\",\n",
       " 'haven',\n",
       " \"haven't\",\n",
       " 'isn',\n",
       " \"isn't\",\n",
       " 'ma',\n",
       " 'mightn',\n",
       " \"mightn't\",\n",
       " 'mustn',\n",
       " \"mustn't\",\n",
       " 'needn',\n",
       " \"needn't\",\n",
       " 'shan',\n",
       " \"shan't\",\n",
       " 'shouldn',\n",
       " \"shouldn't\",\n",
       " 'wasn',\n",
       " \"wasn't\",\n",
       " 'weren',\n",
       " \"weren't\",\n",
       " 'won',\n",
       " \"won't\",\n",
       " 'wouldn',\n",
       " \"wouldn't\"]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "abd9f8e9-6033-42e0-9e40-0bc71acc767d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Natural language processing is that any computation and manipulation of natural language to get inside about how words mean and how sentences are contructed is natural language processing.\n"
     ]
    }
   ],
   "source": [
    "sent=\"Natural language processing is that any computation and manipulation of natural language to get inside about how words mean and how sentences are contructed is natural language processing.\"\n",
    "print(sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "7a88daf7-e514-4801-ae71-22206ad3ee69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Natural', 'language', 'processing', 'is', 'that', 'any', 'computation', 'and', 'manipulation', 'of', 'natural', 'language', 'to', 'get', 'inside', 'about', 'how', 'words', 'mean', 'and', 'how', 'sentences', 'are', 'contructed', 'is', 'natural', 'language', 'processing', '.']\n",
      "['Natural', 'language', 'processing', 'computation', 'manipulation', 'natural', 'language', 'get', 'inside', 'words', 'mean', 'sentences', 'contructed', 'natural', 'language', 'processing', '.']\n"
     ]
    }
   ],
   "source": [
    "words=word_tokenize(sent)\n",
    "words_after_stopwords=[word for word in words if word.lower() not in ls]\n",
    "print(words)\n",
    "print(words_after_stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "ce7b4dfa-81e7-4254-a20e-066daa518d86",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(29, 17)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(words),len(words_after_stopwords)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "191c60e2-0553-49cb-b14a-f52420de5fd4",
   "metadata": {},
   "source": [
    "### Lemmatization & Stemming"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc446584-7d97-41d1-9a4a-154f4a3385e8",
   "metadata": {},
   "source": [
    "Stemming:\n",
    "1. It is a rule base approach hence ended up giving sometimes non-english words.\n",
    "3. It is very fast approach."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "221bf7be-60c9-4b41-9c4c-20cf25f9bc52",
   "metadata": {},
   "outputs": [],
   "source": [
    "sent = \"task tasked tasks tasking keys mangoes computing looking\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "71b500be-faf2-48dd-8aed-05bce059e64e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['task', 'tasked', 'tasks', 'tasking', 'keys', 'mangoes', 'computing', 'looking']\n"
     ]
    }
   ],
   "source": [
    "words=word_tokenize(sent)\n",
    "words_after_stopwords=[word for word in words if word.lower() not in ls]\n",
    "print(words_after_stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "d037e571-a147-44cb-8f89-623f81764d34",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem.porter import PorterStemmer\n",
    "stemmer = PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "47301cf9-d2c4-4f78-93ca-00716fe21917",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['task', 'task', 'task', 'task', 'key', 'mango', 'comput', 'look']\n"
     ]
    }
   ],
   "source": [
    "words_after_stemming=[stemmer.stem(word) for word in words_after_stopwords]\n",
    "print(words_after_stemming)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73d13126-745a-4bb4-a578-b07c607b462b",
   "metadata": {},
   "source": [
    "Lemmatization:\n",
    "1. It is a corpus based approach. It is very lineant approach. It will always be giving you english words.\n",
    "2. It is a slow approach."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "d56af0f5-fe67-49c2-b3fc-ceb0470f0644",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/shivamgarg/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/wordnet.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download(\"wordnet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "0a65e723-add8-4bc5-87b0-1738a326a3a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "wordnet_lemmatizer = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "1f6ec122-abfe-4d8c-89a4-f1520dbc721b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['task', 'tasked', 'tasks', 'tasking', 'keys', 'mangoes', 'computing', 'looking']\n",
      "['task', 'tasked', 'task', 'tasking', 'key', 'mango', 'computing', 'looking']\n"
     ]
    }
   ],
   "source": [
    "words_after_lemmatization=[wordnet_lemmatizer.lemmatize(word) for word in words_after_stopwords]\n",
    "print(words)\n",
    "print(words_after_lemmatization)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b9bbb08-36bb-4c7f-83bd-860559e39936",
   "metadata": {},
   "source": [
    "### Vectorisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "4aba391a-7475-4d0f-b6b0-7ba1b57987f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "ddfbf355-6be6-4838-be20-0e1bd05af21f",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = [\n",
    "    \"The quick brown fox jumps over the lazy dog\",\n",
    "    \"Never jump over the lazy dog quickly\",\n",
    "    \"The dog is not lazy\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "180deffd-e11d-47b8-8297-4673eac50cf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_vectorizer = TfidfVectorizer(stop_words='english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "b949b1a5-891b-4215-a365-1a3cc8bd7829",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_matrix = tfidf_vectorizer.fit_transform(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "4fa1ddda-7707-4e9a-8516-4641284cdf15",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['brown', 'dog', 'fox', 'jump', 'jumps', 'lazy', 'quick', 'quickly'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_names = tfidf_vectorizer.get_feature_names_out()\n",
    "feature_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abd51979-6ceb-42a8-b7b4-588da9ea2312",
   "metadata": {},
   "outputs": [],
   "source": [
    "#feature_names = tfidf_vectorizer.get_feature_names()\n",
    "#feature_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "a641b194-3de6-497f-86a0-a3add4acb0d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "tfidf_df = pd.DataFrame(tfidf_matrix.toarray(), columns=feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "10540620-d685-4645-b811-135a9627bbaf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>brown</th>\n",
       "      <th>dog</th>\n",
       "      <th>fox</th>\n",
       "      <th>jump</th>\n",
       "      <th>jumps</th>\n",
       "      <th>lazy</th>\n",
       "      <th>quick</th>\n",
       "      <th>quickly</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.461381</td>\n",
       "      <td>0.272499</td>\n",
       "      <td>0.461381</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.461381</td>\n",
       "      <td>0.272499</td>\n",
       "      <td>0.461381</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.359594</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.608845</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.359594</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.608845</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.707107</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.707107</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      brown       dog       fox      jump     jumps      lazy     quick  \\\n",
       "0  0.461381  0.272499  0.461381  0.000000  0.461381  0.272499  0.461381   \n",
       "1  0.000000  0.359594  0.000000  0.608845  0.000000  0.359594  0.000000   \n",
       "2  0.000000  0.707107  0.000000  0.000000  0.000000  0.707107  0.000000   \n",
       "\n",
       "    quickly  \n",
       "0  0.000000  \n",
       "1  0.608845  \n",
       "2  0.000000  "
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9acc697-9959-4cb0-98e4-a4ab5b9d5339",
   "metadata": {},
   "source": [
    "<a id=\"12\"></a> <br>\n",
    "# Text Classification\n",
    "*  Classify male and female according to their tweets(description)\n",
    "* import twitter data set from \"Twitter User Gender Classification\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "82f60bca-519f-4528-aded-00049c26e067",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "94f85dde-a2ad-4987-95bc-3360af5401cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(r\"gender-classifier-DFE-791531.csv\",encoding='latin1')\n",
    "data = pd.concat([data.gender,data.description],axis=1)\n",
    "#https://drive.google.com/file/d/10-YHdBzry9hMdrM5ct2JXvQmJN0cm7Fo/view?usp=drive_link"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "3a74ac5b-2139-4be5-ba63-d23fca574692",
   "metadata": {},
   "outputs": [],
   "source": [
    "data=data[data[\"gender\"].isin([\"female\",\"male\"])]\n",
    "# drop nan values\n",
    "data.dropna(inplace=True,axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "13a46e7c-01ee-4719-bc45-15cce9f36e39",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11194, 2)"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "98e28427-ed40-430c-ae35-d3d4332eb9a9",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gender</th>\n",
       "      <th>description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>male</td>\n",
       "      <td>i sing my own rhythm.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>male</td>\n",
       "      <td>I'm the author of novels filled with family dr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>male</td>\n",
       "      <td>louis whining and squealing and all</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>male</td>\n",
       "      <td>Mobile guy.  49ers, Shazam, Google, Kleiner Pe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>female</td>\n",
       "      <td>Ricky Wilson The Best FRONTMAN/Kaiser Chiefs T...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   gender                                        description\n",
       "0    male                              i sing my own rhythm.\n",
       "1    male  I'm the author of novels filled with family dr...\n",
       "2    male                louis whining and squealing and all\n",
       "3    male  Mobile guy.  49ers, Shazam, Google, Kleiner Pe...\n",
       "4  female  Ricky Wilson The Best FRONTMAN/Kaiser Chiefs T..."
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "59ed7643-09d5-4d24-91d9-3ab529549ec0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert genders from female and male to 1 and 0 respectively\n",
    "data.gender = [1 if each == \"female\" else 0 for each in data.gender] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "1555c937-54e7-49b4-8aaa-90ccf1142856",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gender</th>\n",
       "      <th>description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>i sing my own rhythm.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>I'm the author of novels filled with family dr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>louis whining and squealing and all</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>Mobile guy.  49ers, Shazam, Google, Kleiner Pe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>Ricky Wilson The Best FRONTMAN/Kaiser Chiefs T...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   gender                                        description\n",
       "0       0                              i sing my own rhythm.\n",
       "1       0  I'm the author of novels filled with family dr...\n",
       "2       0                louis whining and squealing and all\n",
       "3       0  Mobile guy.  49ers, Shazam, Google, Kleiner Pe...\n",
       "4       1  Ricky Wilson The Best FRONTMAN/Kaiser Chiefs T..."
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "9b927c2a-845e-4e28-b6ac-68c0c32de01b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "0fe2930e-d2b6-49e9-946b-150a07a34442",
   "metadata": {},
   "outputs": [],
   "source": [
    "def processing(sent):\n",
    "    sent = re.sub(r'[^a-zA-Z0-9\\s]', '', sent) # text cleaning (removing punctuations)\n",
    "    words=word_tokenize(sent) # tokenisation\n",
    "    words_after_stopwords=[word for word in words if word.lower() not in stopwords.words('english')] # stopword removal\n",
    "    words_after_stemming=[stemmer.stem(word) for word in words_after_stopwords] # Stemming\n",
    "    return \" \".join(words_after_stemming)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "24562a91-e7d0-4d5d-9c7b-a19c4e8d5c77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4.65 s, sys: 1.15 s, total: 5.8 s\n",
      "Wall time: 5.95 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "data[\"description\"]=data[\"description\"].apply(processing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "eb761d53-0231-4b2f-a450-3020ef7973b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "vect=TfidfVectorizer(max_features=100)\n",
    "X=vect.fit_transform(data.description).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "6789b252-3cb1-47f6-a6ef-e20a9a10b860",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = data.iloc[:,0].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "4541ec47-3ee4-43b0-afce-ef722eb06453",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['18', '19', 'account', 'also', 'alway', 'anim', 'art', 'artist',\n",
       "       'author', 'beauti', 'believ', 'best', 'big', 'blogger', 'book',\n",
       "       'busi', 'call', 'come', 'day', 'de', 'design', 'dont', 'dream',\n",
       "       'editor', 'enthusiast', 'famili', 'fan', 'father', 'find',\n",
       "       'follow', 'food', 'footbal', 'free', 'friend', 'fuck', 'game',\n",
       "       'get', 'girl', 'go', 'god', 'good', 'got', 'happi', 'heart',\n",
       "       'husband', 'ig', 'im', 'instagram', 'know', 'life', 'like',\n",
       "       'littl', 'live', 'look', 'love', 'lover', 'make', 'man', 'manag',\n",
       "       'market', 'media', 'mom', 'music', 'name', 'never', 'new', 'old',\n",
       "       'one', 'opinion', 'passion', 'peopl', 'person', 'play',\n",
       "       'profession', 'proud', 'real', 'right', 'say', 'snapchat',\n",
       "       'social', 'sport', 'student', 'take', 'thing', 'time', 'travel',\n",
       "       'tri', 'tweet', 'twitter', 'univers', 'video', 'view', 'want',\n",
       "       'way', 'work', 'world', 'write', 'writer', 'year', 'your'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_names = vect.get_feature_names_out()\n",
    "feature_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "7c97a32f-4cd4-4735-8b76-7649437e7331",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_df = pd.DataFrame(X, columns=feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "37ce6ba5-f87b-4098-942a-a709f4816a70",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "      <th>account</th>\n",
       "      <th>also</th>\n",
       "      <th>alway</th>\n",
       "      <th>anim</th>\n",
       "      <th>art</th>\n",
       "      <th>artist</th>\n",
       "      <th>author</th>\n",
       "      <th>beauti</th>\n",
       "      <th>believ</th>\n",
       "      <th>best</th>\n",
       "      <th>big</th>\n",
       "      <th>blogger</th>\n",
       "      <th>book</th>\n",
       "      <th>busi</th>\n",
       "      <th>call</th>\n",
       "      <th>come</th>\n",
       "      <th>day</th>\n",
       "      <th>de</th>\n",
       "      <th>design</th>\n",
       "      <th>dont</th>\n",
       "      <th>dream</th>\n",
       "      <th>editor</th>\n",
       "      <th>enthusiast</th>\n",
       "      <th>famili</th>\n",
       "      <th>fan</th>\n",
       "      <th>father</th>\n",
       "      <th>find</th>\n",
       "      <th>follow</th>\n",
       "      <th>food</th>\n",
       "      <th>footbal</th>\n",
       "      <th>free</th>\n",
       "      <th>friend</th>\n",
       "      <th>fuck</th>\n",
       "      <th>game</th>\n",
       "      <th>get</th>\n",
       "      <th>girl</th>\n",
       "      <th>go</th>\n",
       "      <th>god</th>\n",
       "      <th>good</th>\n",
       "      <th>got</th>\n",
       "      <th>happi</th>\n",
       "      <th>heart</th>\n",
       "      <th>husband</th>\n",
       "      <th>ig</th>\n",
       "      <th>im</th>\n",
       "      <th>instagram</th>\n",
       "      <th>know</th>\n",
       "      <th>life</th>\n",
       "      <th>like</th>\n",
       "      <th>littl</th>\n",
       "      <th>live</th>\n",
       "      <th>look</th>\n",
       "      <th>love</th>\n",
       "      <th>lover</th>\n",
       "      <th>make</th>\n",
       "      <th>man</th>\n",
       "      <th>manag</th>\n",
       "      <th>market</th>\n",
       "      <th>media</th>\n",
       "      <th>mom</th>\n",
       "      <th>music</th>\n",
       "      <th>name</th>\n",
       "      <th>never</th>\n",
       "      <th>new</th>\n",
       "      <th>old</th>\n",
       "      <th>one</th>\n",
       "      <th>opinion</th>\n",
       "      <th>passion</th>\n",
       "      <th>peopl</th>\n",
       "      <th>person</th>\n",
       "      <th>play</th>\n",
       "      <th>profession</th>\n",
       "      <th>proud</th>\n",
       "      <th>real</th>\n",
       "      <th>right</th>\n",
       "      <th>say</th>\n",
       "      <th>snapchat</th>\n",
       "      <th>social</th>\n",
       "      <th>sport</th>\n",
       "      <th>student</th>\n",
       "      <th>take</th>\n",
       "      <th>thing</th>\n",
       "      <th>time</th>\n",
       "      <th>travel</th>\n",
       "      <th>tri</th>\n",
       "      <th>tweet</th>\n",
       "      <th>twitter</th>\n",
       "      <th>univers</th>\n",
       "      <th>video</th>\n",
       "      <th>view</th>\n",
       "      <th>want</th>\n",
       "      <th>way</th>\n",
       "      <th>work</th>\n",
       "      <th>world</th>\n",
       "      <th>write</th>\n",
       "      <th>writer</th>\n",
       "      <th>year</th>\n",
       "      <th>your</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.628864</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.636808</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.446101</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.409947</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.815039</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.409456</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    18   19  account  also     alway  anim  art  artist    author  beauti  \\\n",
       "0  0.0  0.0      0.0   0.0  0.000000   0.0  0.0     0.0  0.000000     0.0   \n",
       "1  0.0  0.0      0.0   0.0  0.000000   0.0  0.0     0.0  0.628864     0.0   \n",
       "2  0.0  0.0      0.0   0.0  0.000000   0.0  0.0     0.0  0.000000     0.0   \n",
       "3  0.0  0.0      0.0   0.0  0.000000   0.0  0.0     0.0  0.000000     0.0   \n",
       "4  0.0  0.0      0.0   0.0  0.409947   0.0  0.0     0.0  0.000000     0.0   \n",
       "\n",
       "   believ      best  big  blogger  book  busi  call  come  day   de  design  \\\n",
       "0     0.0  0.000000  0.0      0.0   0.0   0.0   0.0   0.0  0.0  0.0     0.0   \n",
       "1     0.0  0.000000  0.0      0.0   0.0   0.0   0.0   0.0  0.0  0.0     0.0   \n",
       "2     0.0  0.000000  0.0      0.0   0.0   0.0   0.0   0.0  0.0  0.0     0.0   \n",
       "3     0.0  0.000000  0.0      0.0   0.0   0.0   0.0   0.0  0.0  0.0     0.0   \n",
       "4     0.0  0.815039  0.0      0.0   0.0   0.0   0.0   0.0  0.0  0.0     0.0   \n",
       "\n",
       "   dont  dream  editor  enthusiast    famili  fan  father  find  follow  food  \\\n",
       "0   0.0    0.0     0.0         0.0  0.000000  0.0     0.0   0.0     0.0   0.0   \n",
       "1   0.0    0.0     0.0         0.0  0.636808  0.0     0.0   0.0     0.0   0.0   \n",
       "2   0.0    0.0     0.0         0.0  0.000000  0.0     0.0   0.0     0.0   0.0   \n",
       "3   0.0    0.0     0.0         0.0  0.000000  0.0     0.0   0.0     0.0   0.0   \n",
       "4   0.0    0.0     0.0         0.0  0.000000  0.0     0.0   0.0     0.0   0.0   \n",
       "\n",
       "   footbal  free  friend  fuck  game  get  girl   go  god  good  got  happi  \\\n",
       "0      0.0   0.0     0.0   0.0   0.0  0.0   0.0  0.0  0.0   0.0  0.0    0.0   \n",
       "1      0.0   0.0     0.0   0.0   0.0  0.0   0.0  0.0  0.0   0.0  0.0    0.0   \n",
       "2      0.0   0.0     0.0   0.0   0.0  0.0   0.0  0.0  0.0   0.0  0.0    0.0   \n",
       "3      0.0   0.0     0.0   0.0   0.0  0.0   0.0  0.0  0.0   0.0  0.0    0.0   \n",
       "4      0.0   0.0     0.0   0.0   0.0  0.0   0.0  0.0  0.0   0.0  0.0    0.0   \n",
       "\n",
       "   heart  husband   ig        im  instagram  know  life  like  littl  live  \\\n",
       "0    0.0      0.0  0.0  0.000000        0.0   0.0   0.0   0.0    0.0   0.0   \n",
       "1    0.0      0.0  0.0  0.446101        0.0   0.0   0.0   0.0    0.0   0.0   \n",
       "2    0.0      0.0  0.0  0.000000        0.0   0.0   0.0   0.0    0.0   0.0   \n",
       "3    0.0      1.0  0.0  0.000000        0.0   0.0   0.0   0.0    0.0   0.0   \n",
       "4    0.0      0.0  0.0  0.000000        0.0   0.0   0.0   0.0    0.0   0.0   \n",
       "\n",
       "   look  love  lover  make  man  manag  market  media  mom  music  name  \\\n",
       "0   0.0   0.0    0.0   0.0  0.0    0.0     0.0    0.0  0.0    0.0   0.0   \n",
       "1   0.0   0.0    0.0   0.0  0.0    0.0     0.0    0.0  0.0    0.0   0.0   \n",
       "2   0.0   0.0    0.0   0.0  0.0    0.0     0.0    0.0  0.0    0.0   0.0   \n",
       "3   0.0   0.0    0.0   0.0  0.0    0.0     0.0    0.0  0.0    0.0   0.0   \n",
       "4   0.0   0.0    0.0   0.0  0.0    0.0     0.0    0.0  0.0    0.0   0.0   \n",
       "\n",
       "   never  new  old  one  opinion  passion  peopl  person  play  profession  \\\n",
       "0    0.0  0.0  0.0  0.0      0.0      0.0    0.0     0.0   0.0         0.0   \n",
       "1    0.0  0.0  0.0  0.0      0.0      0.0    0.0     0.0   0.0         0.0   \n",
       "2    0.0  0.0  0.0  0.0      0.0      0.0    0.0     0.0   0.0         0.0   \n",
       "3    0.0  0.0  0.0  0.0      0.0      0.0    0.0     0.0   0.0         0.0   \n",
       "4    0.0  0.0  0.0  0.0      0.0      0.0    0.0     0.0   0.0         0.0   \n",
       "\n",
       "   proud  real  right  say  snapchat  social  sport  student  take  thing  \\\n",
       "0    0.0   0.0    0.0  0.0       0.0     0.0    0.0      0.0   0.0    0.0   \n",
       "1    0.0   0.0    0.0  0.0       0.0     0.0    0.0      0.0   0.0    0.0   \n",
       "2    0.0   0.0    0.0  0.0       0.0     0.0    0.0      0.0   0.0    0.0   \n",
       "3    0.0   0.0    0.0  0.0       0.0     0.0    0.0      0.0   0.0    0.0   \n",
       "4    0.0   0.0    0.0  0.0       0.0     0.0    0.0      0.0   0.0    0.0   \n",
       "\n",
       "   time  travel  tri  tweet  twitter  univers  video  view  want  way  work  \\\n",
       "0   0.0     0.0  0.0    0.0      0.0      0.0    0.0   0.0   0.0  0.0   0.0   \n",
       "1   0.0     0.0  0.0    0.0      0.0      0.0    0.0   0.0   0.0  0.0   0.0   \n",
       "2   0.0     0.0  0.0    0.0      0.0      0.0    0.0   0.0   0.0  0.0   0.0   \n",
       "3   0.0     0.0  0.0    0.0      0.0      0.0    0.0   0.0   0.0  0.0   0.0   \n",
       "4   0.0     0.0  0.0    0.0      0.0      0.0    0.0   0.0   0.0  0.0   0.0   \n",
       "\n",
       "   world  write  writer      year  your  \n",
       "0    0.0    0.0     0.0  0.000000   0.0  \n",
       "1    0.0    0.0     0.0  0.000000   0.0  \n",
       "2    0.0    0.0     0.0  0.000000   0.0  \n",
       "3    0.0    0.0     0.0  0.000000   0.0  \n",
       "4    0.0    0.0     0.0  0.409456   0.0  "
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "58b09f56-5cfc-4123-ac1a-9e0eba41b51e",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option(\"display.max_columns\", None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04fead71-8826-4b30-8fcb-dd7ba6d7ab32",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
